{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python SQL Tutorial\n",
    "\n",
    "Mark V. Andersen\n",
    "\n",
    "August 2019\n",
    "\n",
    "### Prerequisites and Setup\n",
    "Prerequisite: Getting Started with Data Analytics Tutorial\n",
    "\n",
    "**Download**: chinook.db file\n",
    "**Install**: sqlalchemy with conda before running jupyter\n",
    "\n",
    "### Objectives\n",
    "\n",
    "* Learn how to retrieve SQL data into a dataframe\n",
    "* Learn how to perform merges (equivalent to SQL joins) with dataframes\n",
    "* Optionally: Practice making charts with data\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "chinook.db is a sample SQLite database which contains information about music.  Learning how to query a SQLLite database with SQL creates transferrable skills for querying other databases with SQL.\n",
    "\n",
    "The database includes tables with albums, artists, tracks, genres, and more.  In this tutorial you will create dataframes from several tables, and then merge these dataframes, and create charts.  Along the way you will see how outer joins work with pandas.\n",
    "\n",
    "This tutorial is based on a disk based sql database (SQLLite) which is said to be the most common sql database in the world today.  SQLLite is used to make this tutorial accessible to all users.\n",
    "\n",
    "Your own database may be accessed with adoptions of this code.  You may find in your own instance that you have to install pyodbc or another driver.\n",
    "\n",
    "This tutorial is inspired by:\n",
    "* http://www.sqlitetutorial.net/sqlite-python/sqlite-python-select/\n",
    "* http://www.sqlitetutorial.net/sqlite-sample-database/ - db schema for chinook.db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the libraries are installed:\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "# If this step causes an error you may have to shut down jupyter, install needed libraries and relaunch again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the database chinhook.db\n",
    "\n",
    "Note: Wihout a specified path, sqllite will search for database in the same directory which contains this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "# Create a connection to the database for the tutorial\n",
    "database = \"chinook.db\"\n",
    "conn = sqlite3.connect(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple query verifies we can access the chinook database\n",
    "\n",
    "You should see five rows of data on albums when you run the cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM albums limit 5\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warmup Exercises: Strings, Lists, Print (with f-strings)\n",
    "\n",
    "Lists are fundamental to python.\n",
    "\n",
    "Run each of these cells and review what they are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings v. lists\n",
    "\n",
    "# - Strings\n",
    "# strings have single quotes:\n",
    "this_is_a_string = 'myfullname'\n",
    "# or double quotes if you prefer:\n",
    "this_is_also_a_string = \"myfullname\"\n",
    "\n",
    "# - Lists\n",
    "# lists are denoted with square brackets and contain objects which could be strings or numbers:\n",
    "this_is_a_list = ['my', 'full', 'name']\n",
    "this_is_also_a_list = [1, 2, 3, 4]\n",
    "this_is_a_mixed_list = [1, 'happy', 2, 'sad']\n",
    "# PEP8 defines standards for syntax and spacing in python.  Spaces after commas are standard for lists (see above).\n",
    "\n",
    "# - Print out the string and list variables\n",
    "print('Variables:')\n",
    "print(this_is_a_string)\n",
    "print(this_is_a_list)\n",
    "print(this_is_a_mixed_list)\n",
    "\n",
    "# - type function\n",
    "# we can check the type of any object with the type command:\n",
    "print()\n",
    "print('Types:')\n",
    "print(f'this_is_a_string has type: {type(this_is_a_string)}')\n",
    "print(f'this_is_a_list has type: {type(this_is_a_list)}')\n",
    "print(f'this_is_a_mixed_list has type: {type(this_is_a_mixed_list)}')\n",
    "\n",
    "# the print statements above used f-strings\n",
    "# f-strings allow you to mix literal text and computed python variables in {}'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists can be accessed by selecting an element with an indexer in square brackets, where item [0] is the first\n",
    "# aka zero-based-indexing:\n",
    "columns = ['a', 'b', 'c', 'd']\n",
    "print(f'Columns is: {columns}')\n",
    "print(f'First element of columns: {columns[0]}')\n",
    "\n",
    "# f-strings:\n",
    "#  Note the f in front of the string causes it to look for the curly braces inside\n",
    "#  and then it runs the code in the curly braces\n",
    "#\n",
    "i = 2\n",
    "print(f'This is element {i} of the string named columns: {columns[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration over lists in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to iterate in python\n",
    "#\n",
    "# Notice that when you do a loop or function it is one level indented and there is a mandatory colon for the line\n",
    "# which introduces the loop\n",
    "for i in columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration over a string in python -- be careful to notice what you have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same iteration code would work over a string, but produces different results\n",
    "#\n",
    "# When you use pandas if you pass in a string where a list is expected you may encounter a KeyError\n",
    "# becuase it looks for a letter in the column name when you intended to get the whole column name.\n",
    "#\n",
    "# Watch out for whether functions require a list or string as you use pandas.\n",
    "#\n",
    "columns = 'myfullname'\n",
    "for i in columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Exercises: SQL Syntax With Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Retrieve \"albums\" table into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sample code and examine the info() about the DataFrame\n",
    "sql_query = 'select * from albums'\n",
    "albums_df = pd.read_sql(sql_query, conn)\n",
    "print(albums_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Create a new dataframe for \"artists\" table\n",
    "\n",
    "* Create the dataframe artists_df, holding rows from the artists table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use example above, but this time the datatable is called artists\n",
    "# Your code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Merge the albums and artists dataframes\n",
    "\n",
    "* Pandas join function supports several types of joins, most importantly 'inner' and 'left'\n",
    "* Invoke the join function on one dataframe (the left one) and pass in the right dataframe.  \n",
    "* left_on can specify the column in the left dataframe for joining\n",
    "* right_on can specify the column in the right dataframe for joining\n",
    "* *indicator=True* will cause a column called _merge to be created with the results of the join\n",
    "* Assign the merged data to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this sample code to merge albums and artists into a new DataFrame\n",
    "album_artists_df = albums_df.merge(artists_df, \n",
    "                                   how='left', \n",
    "                                   left_on='ArtistId', \n",
    "                                   right_on='ArtistId', \n",
    "                                   indicator=True)\n",
    "album_artists_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Print out the frequency distribution for the column: _merge\n",
    "\n",
    "* Hint: value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Review the _merge counts and then drop that column from the DataFrame.\n",
    "\n",
    "* Confirm that there were no nulls merged with the left join (all records are 'both').\n",
    "* Now the _merge column does not look interesting to keep around\n",
    "* Drop the column in one of two ways.  Either:\n",
    "  * call the drop function and ensure that the column actually is dropped (notice the inplace argument)\n",
    "  * paste in the merge again below but this time with the indicator off and perhaps using the inner join rather than left join (since all records matched).\n",
    "\n",
    "* Pandas documentation for drop: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
    "* Pandas documentation for merge: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "\n",
    "Notes:\n",
    "* Notice that the drop command takes a list of columns to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Load the \"tracks\" db table into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Merge the tracks with the album_artists_df above\n",
    "\n",
    "* Do a left join with a merge indicator\n",
    "\n",
    "\n",
    "* Note: You cannot have a second _merge indicator if you already have one.  You may need to drop that column first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Clean up the Name field\n",
    "\n",
    "* Notice that Name_x and Name_y fields exist when you look at info\n",
    "* Both tables had a column called Name before the merge\n",
    "  * Name_x is from the left dataframe\n",
    "  * Name_y is from the right dataframe\n",
    "\n",
    "* Print out the Name fields and notice how the contents are different\n",
    "* Rename one of the fields to a more logical name prior to running a join\n",
    "* Repeat the join so you have two differently named fields which make more sense than Name_x and Name_y\n",
    "* You can accomplish this either here, or by going back above before the merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Import table \"genres\" into a dataframe\n",
    "\n",
    "* Print out the Genres from this new dataframe and notice what they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10: Merge the genres into the prior dataframe\n",
    "\n",
    "* Note: You cannot have a second _merge indicator if you already have one.  You may need to drop that column first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Main Exercises\n",
    "\n",
    "\n",
    "\n",
    "# Additional Exercises to Gain Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11: Scatter plot milliseconds v. bytes\n",
    "\n",
    "* Use the merged dataframe from earlier exericses\n",
    "\n",
    "Hint: pandas has a plot.scatter() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12: Make two charts: one for Rock and one for non-Rock genres\n",
    "\n",
    "* Color the points red if the genre = \"Rock\"\n",
    "* Color the points blue if the genre != \"Rock\"\n",
    "* Set the figsize to (12,10) so it's larger\n",
    "\n",
    "Hint: You will need to call plot twice to make two charts.\n",
    "\n",
    "Recall: Get a subset of a dataframe using [] conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13: Combine the two plots into a single plot\n",
    "\n",
    "* By capturing the return from the first plot as a variable and then passing that in as the ax argument to the second\n",
    "plot you can cause the plots to superimpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 14: Repeat but trim outliers out of the chart\n",
    "\n",
    "Hint: slice the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 15: Save the figure to disk\n",
    "\n",
    "* If you want to get fancy, add a title, xlabel, ylabel; set the font size for them, improve the tick indicators on the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 16: Histogram number of tracks of each genre\n",
    "\n",
    "* This may be a bit tricky.  An option is a group by and count.  Another is to do a crosstab and plot that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
